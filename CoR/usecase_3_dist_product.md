# Скрабирующий графовый алгоритм с фикс. параметрами на выборках из всех комбинаций распределений, отчёт с метриками в пдф формате

1. Использовать алгоритм (**Юзер**)
   1. Импортировать из steps/test_execution_step/algorithms графовый алгоритм
2. Генерация данных
   1. Создаем директорию **generator_name** в /steps/data_generation_step (**Программист**)
   2. Наследуемся от интерфейса DataHandler. Вызываем генерацию датасетов с помощью реализованных генераторов (нормального, стьюдента и экспоненциального распределений), перемешиваем и создаем 3 датасета по 100 элементов. 
   3. Реализуем метод write_data. С помощью Storage заполняем сгенерированные данные в DataBase. (**Программист**)
   4. Импортируем в наше решение (**Юзер**)
3. Обработка результата
   1. Создаем директорию **report_builder_name** в /steps/report_generation_step/reporters (**Программист**)
   2. Наследуемся от интерфейса ReportBuilder. 
   3. Реализуем метод build. Он вычисляет и записывает в свои поля confusion matrix, f1-score, время работы (**Программист**)
   4. Создаем директорию **report_visualizer_name** в /steps/report_generation_step/visualizers (**Программист**)
   5. Наследуемся от интерфейса ReportVisualizer. И реализуем метод draw, который строит график и записывает результаты в pdf (**Юзер**)
4. Создаем пайплайн (**Юзер**)
   1. В pipline создаем скрипт, инициализируем объекта pipeline
   2. Передаем туда степ генератора, указав поля для сохранения данных
   3. Инициализируем графовый алгоритм параметрами, указываем поля откуда берем данные и куда кладём 
   4. Передаем в пайплайн созданный репортер визуализатор, указывает поля откуда берём данные
   5. Запускаем пайплайн, получаем сообщения о ходе работы
   6. После выполнения сохраняется лог в /execution_logs
5. Обработка результатов (**Юзер**)
   1. Резльтат сохранен в pdf файл в /results
   2. Открываем и анализируем
