# Добавить реализацию СКРАБИРУЮЩЕГО algo_name алгоритма в CPD библиотеку.

1. Реализовать алгоритм
    1. Создать директорию **algo_name** в /algorithms и реализовать там алгоритм унаследованный
    2. В /algorithms создать файл **algo_name.py** и унаследовать свой алгоритм от абстрактного класса
       OfflineAlgorithm, подключив реализацию из /algorithms/**algo_name**.
    3. Реализовать 2 разных метода дла детекции (detect) и локализации (localize) разладки.
2. Протестировать алгоритм
    1. Создать файл/директорию test_**algo_name**.py/test_**algo_name**.
    2. Протестировать каждый метод алгоритма (unit test).
    3. Интеграционное тестирование для методов detect, localize.
3. Генерация данных
    1. В директории /steps/data_handlers находятся обработчики данных для создания/чтения. Выбираем один из
       представленных генераторов для синтеза данных.
    2. Если подходящего генератора нет, то:
        1. Создаем файл **generator_name.py** и при необходимости директорию **generator_name** (для более сложной
           реализации)
           в /steps/workers
        2. Наследуемся от интерфейса DataHandter. И реализуем метод write_data. С помощью Storage заполняем
           сгенерированные данные в DataBase.
    3. Для большинства генераторов нужны конфиги (Пример такого конфига normal_normal_config.yaml). Там задаются
       распределения. Первая часть - нормальное распределение длинны 200, матожидание 0.1, среднеквадратичное отклонение
       0.5. Так же задаются все части, которые будут последовательно соединены в один датасет.
    4. Далее этот генератор будем называть **NormalGenerator**.
4. Настроить мета-параметры
    1. В директории /steps/workers находятся воркеры для исполнения. Одним из таких исполнений может быть подбор
       мета-параметров.
    2. Если есть подходящий воркер для нового алгоритма (например для подбора порога), то используем его. Иначе:
        1. Создаем файл **worker_name.py** и при необходимости директорию **worker_name** (для более сложной реализации)
           в /steps/workers
        2. Наследуемся от интерфейса Worker. И реализуем метод handle. С помощью Storage сохраняем результаты в DataBase
        3. Метод handle в нашем случе возвращает словарь {**название_мета-параметра** -> **результат_подбора**}
    3. Далее этот воркер будем называть **SelectionWorker**.
    4. Так же создаем Worker для обработки данных нашим алгоритмом и сохранением в БД результатов. (**ExecutionWorker**.)
5. Обработка результата
    1. В директории /steps/reporters/builders находятся обработчики результатов работы. Выбираем один из представленных
       обработчиков.
    2. Если подходящего Билдера нет, то:
        1. Создаем файл **builder_name.py** и при необходимости директорию **builder_name** (для более сложной
           реализации) в /steps/reporters/builders
        2. Наследуемся от интерфейса ReportBuilder. И реализуем метод build. Он записывает нужную информацию в свои
           поля (списки матожиданий, диперсий, мощностей)
    3. В директории /steps/reporters/directors находятся Визуализаторы обработанных результатов. Выбираем один из
       представленных
       Визуализаторов.
    4. Если подходящего Визуализатора нет, то:
        1. Создаем файл **director_name.py** и при необходимости директорию **director_name** (для более сложной
           реализации) в /steps/reporters/builders
        2. Наследуемся от интерфейса ReportDirector. И реализуем метод draw для отрисовки и сохранения графиков в pdf.
    5. Далее этот репортер будем называть **GraphReporter**.
6. Оценить качество
    1. Создаем конфиг для генерации большего количества датасетов с нормальным распределением.
    2. Создаем DataGenerationStep (name=**NormalGenerationStep**). Туда передается **NormalGenerator** и Storage (туда
       будут сохраняться данные).
    3. Так же заполняем поля _input_data_names_ (None) и _output_data_names_ (названия параметров, по которым данные
       записываются в БД). В нашем случае _input_data_names_ = None,
       _output_data_names_ = ['TIME_SERIES', 'MEAN', 'VARIANCE']
    4. Создаем первый ExecutionStep (name=**SelectionStep**). Он будет подбирать мета-параметры и передавать их в
       следующий шаг. Для
       этого он должен наследоваться от StepWithOutput. Необходимо указать _input_data_names_, _output_data_names_,
       _handle_output_data_names_. Соответственно ['TIME_SERIES'], None, ['THRESHOLD']. Передаем **SelectionWorker**.
    5. Создаем второй ExecutionStep (name=**ExecutionStep**). Он будет принимать мета-параметры с предыдущего шага. Для
       этого он должен наследоваться от StepWithInput. Необходимо указать _input_data_names_, _output_data_names_,
       _handle_input_data_names_. Соответственно ['TIME_SERIES'], ['PREDICTED_CP', 'REAL_CP'], ['THRESHOLD']. И передать
       **ExecutionWorker**.
    6. Создаем ReportGenerationStep (name=**GraphReportStep**). Необходимо указать _input_data_names_,
       _output_data_names_. Соответственно ['PREDICTED_CP', 'REAL_CP'], []. И передать
       **GraphReporter**.
    7. Передаем все вышеперечисленные шаги в pipeline. При запуске получаем вывод:
        - NormalGenerationStep: OK
        - SelectionStep: OK
        - ExecutionStep: OK
        - GraphReporter: OK
        - PIPELINE FINISHED