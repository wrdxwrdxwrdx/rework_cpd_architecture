# Просто сгенерировать 3 датасета по конфигам и сохранить для дальнейшего использования

(Хороший вопрос поднялся: может ли в пайплайне быть один шаг? Не упадёт ли всё? Если обязательно 3 шага, то нужно ли сделать вид пустого шага?)
(Да и вообще, опишу как сам бы это закодил, вариантов как это сделать несколько, опишу в конце)

1. Существующие 2 генератора (**Юзер**)
   1. Из директории /steps/data_generation_step импортируем **step**ы для распределений
   2. Пишем конфиги для распределения (например, normal_normal_config.yaml)
2. Реализация ещё одного генератора (**Программист**)
   1. Создаем директорию **generator_name** в /steps/data_generation_step
   2. Наследуемся от интерфейса DataHandler. И реализуем нашу логику и метод write_data. С помощью Storage заполняем сгенерированные данные в DataBase.
   3. Импортируем в наше решение
3. Степ для сохранения (**Программист**)
   1. Создаем директорию worker_name в /test_execution_step/workers
   2. Наследуемся от интерфейса Worker. И реализуем нашу логику(сохранения данных) и метод handle.
   3. Импортируем в наше решение
4. Создаем пайплайн (**Юзер**)
   1. В pipline создаем скрипт, инициализируем pipeline
   2. Передаем в пайплайн генераторы, _input_data_names = None, output_data_names = [поля]_
   3. Передаем в пайплайн нового воркера _input_data_names = [много полей], output_data_names = None_
   4. Запускаем
5. Результат (**Юзер**)
   1. Получаем сохраненные как нам надо(как мы сами закодили) датасеты

---

(Ещё были варианты сделать так: 
1. сделать генератор таким, чтобы он как нам надо сохранял
2. пропустить алгостеп(или вставить заглушку какую-то) и сделать репортер, который это сохранит
хз кароч надо думать)
