# Просто сгенерировать 3 датасета по конфигам и сохранить для дальнейшего использования

(Хороший вопрос поднялся: может ли в пайплайне быть один шаг? Не упадёт ли всё? Если обязательно 3 шага, то нужно ли сделать вид пустого шага?)
(Да и вообще, опишу как сам бы это закодил, вариантов как это сделать несколько, опишу в конце)

1. Существующие 2 генератора (**Юзер**)
   1. Из директории /steps/data_generation_step импортируем **step**ы для распределений
   2. Пишем конфиги для распределения (например, normal_normal_config.yaml)
2. Реализация ещё одного генератора
   1. Создаем директорию **generator_name** в /steps/data_generation_step (**Программист**)
   2. Наследуемся от интерфейса DataHandler. И реализуем нашу логику и метод write_data. С помощью Storage заполняем сгенерированные данные в DataBase. (**Программист**)
   3. Импортируем в наше решение (**Юзер**)
3. Степ для сохранения
   1. Создаем директорию worker_name в /test_execution_step/workers (**Программист**)
   2. Наследуемся от интерфейса Worker. И реализуем нашу логику(сохранения данных) и метод handle. (**Программист**)
   3. Импортируем в наше решение (**Юзер**)
4. Создаем пайплайн (**Юзер**)
   1. В pipline создаем скрипт, инициализируем pipeline
   2. Передаем в пайплайн генераторы, конфиги и имена полей для сохранения данных
   3. Передаем в пайплайн нового воркера и имена полей откуда берём данные
   4. Запускаем
5. Результат (**Юзер**)
   1. Получаем сохраненные как нам надо(как мы сами закодили) датасеты

---

(Ещё были варианты сделать так: 
1. сделать генератор таким, чтобы он как нам надо сохранял
2. пропустить алгостеп(или вставить заглушку какую-то) и сделать репортер, который это сохранит
хз кароч надо думать)
