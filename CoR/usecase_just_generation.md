# Просто сгенерировать 3 датасета по конфигам и сохранить для дальнейшего использования

(Хороший вопрос поднялся: может ли в пайплайне быть один шаг? Не упадёт ли всё? Если обязательно 3 шага, то нужно ли сделать вид пустого шага?)
(Да и вообще, опишу как сам бы это закодил, вариантов как это сделать несколько, опишу в конце)

1. Существующие 2 генератора (**Юзер**)
   1. Из директории /steps/data_generation_step импортируем **step**ы для нормального и стьюдента распределений
   2. Пишем конфиги для распределения, указывая степень свободы и кол-во элементов (1000)
2. Реализация ещё одного генератора
   1. Создаем директорию **generator_name** в /steps/data_generation_step (**Программист**)
   2. Наследуемся от интерфейса DataHandler. Реализуем создание распределения и метод write_data. С помощью Storage заполняем сгенерированные данные в DataBase. (**Программист**)
   3. Импортируем в наше решение (**Юзер**)
3. Степ для сохранения
   1. Создаем директорию worker_name в /test_execution_step/workers (**Программист**)
   2. Наследуемся от интерфейса Worker
   3. Реализуем логику сохранения сгенерированных данных в формате csv в методе handle. (**Программист**)
   4. Импортируем в наше решение (**Юзер**)
4. Создаем пайплайн (**Юзер**)
   1. В pipline создаем скрипт, инициализируем pipeline
   2. Передаем в пайплайн генераторы, конфиги и имена полей для сохранения данных
   3. Передаем в пайплайн нового воркера для сохранения и имена полей откуда берём данные
   4. Запускаем
   5. В /execution_logs получаем лог исполнения
5. Результат (**Юзер**)
   1. Получаем сохраненные в csv датасеты

---

(Ещё были варианты сделать так: 
1. сделать генератор таким, чтобы он как нам надо сохранял
2. пропустить алгостеп(или вставить заглушку какую-то) и сделать репортер, который это сохранит
хз кароч надо думать)
